# *************************************
# Created by: Kukpyo (Andrew) Han  - kha107@sfu.ca
# Created on: March 20, 2022
# Last Updated on: April 1, 2022
# Objective: This python code is intended to read the cleaned parquet files generated by "jobpost_cleaner.py"
#            and push all the records to MongoDB.
# Input files (before processing): located under "/postprocessing_parquet"
# Input files (after processing): located under "/postprocessing_parquet/archive"
# Output files : None
# *************************************


from mongodb_connector import connect_to_collection
import pandas as pd
import numpy as np
import glob
import os
import re
from datetime import datetime


def dict_constructor(jobid, job_title, job_type, job_exp, company, industries, location, source, search_kw,
                     expected_salary, post_date, job_function, remote, job_summary, description):
    output_dict = {
        'id': jobid,
        'job_title': job_title,
        'job_type': job_type,
        'job_exp': job_exp,
        'company': company,
        'industries': industries,
        'location': location,
        'source': source,
        'search_kw': search_kw,
        'expected_salary': expected_salary,
        'post_date': post_date,
        'job_function': job_function,
        'remote': remote,
        'job_summary': job_summary,
        'description': description
    }

    return output_dict


if __name__ == "__main__":

    INPUT_PATH = r'postprocessing_parquet/'
    all_files = glob.glob(INPUT_PATH + "*.parquet")
    TIMESTAMP = datetime.today().strftime("%Y%m%d%H")

    # li is used to hold dataframes taken from the integrated_parquet folder.
    li = []

    print('============================== Read in the parquet files ===================================')

    for filename in all_files:
        df = pd.read_parquet(filename, columns=None)
        li.append(df)

    print('============================== Read in the parquet files (completed) ===================================')

    print('============================== Construct a dictionary for batch insert ===================================')
    # docs_to_insert will hold all the records to be inserted into "JobPosts" collection
    docs_to_insert = []
    for idx_df, df in enumerate(li):
        for idx_row, row in df.iterrows():
            jobpost_dict = dict_constructor(row['id'], row['job_title'], row['job_type'], row['job_exp'],
                                            row['company'], row['industries'], row['location'], row['source'],
                                            row['search_kw'], row['expected_salary'], row['post_date'],
                                            row['job_function'], row['remote'], row['job_summary'], row['description']
                                            )
            docs_to_insert.append(jobpost_dict)
    print('============================== Construct a dictionary for batch insert (completed) ==================='
          '================')

    print('============================== Connecting to MongoDB ===================================')
    # Connect to MongoDB and obtain "JobPosts" collection
    jobpost_collect = connect_to_collection("JobPosts")
    print('============================== Connecting to MongoDB (completed) ===================================')

    print('============================== Inserting into MongoDB ===================================')
    result = jobpost_collect.insert_many(docs_to_insert)
    print("Number of documents added: ", len(result.inserted_ids))
    print("New documents added: ", result.inserted_ids)
    print('============================== Inserting into MongoDB (completed) ===================================')

    print('============================== Move the processed files to archive ===================================')

    # Move the processed parquet files to archive folder.
    for filename in all_files:
        # Extract the file name from the full path.
        filename_tmp1 = filename.split("\\")
        # Source file path
        source = filename
        # destination file path
        dest = INPUT_PATH + "archive/" + filename_tmp1[1]

        try:
            os.rename(source, dest)
            print(f"{filename_tmp1[1]} : Source path renamed to destination path successfully.")
        # For permission related errors
        except PermissionError:
            print("Operation not permitted.")
        # For other errors
        except OSError as error:
            print(error)

    print('============================== Move the processed files to archive (completed) ====================='
          '=============')